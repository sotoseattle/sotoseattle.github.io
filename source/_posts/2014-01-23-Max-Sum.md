---
layout: post
title: "Factors Sum and Max_Marginalization"
date: 2014-01-23 08:01
comments: true
categories: PGN, theory
---

We can use the same inference engine based on clique trees to not only find the exact marginals but also the most probable assignments (MAP: Maximum A Posteriori).

We'll first change from probabilities to log-proabilities for all factor values to avoid underflows since all product operations becomes sums. Then, factor sum is, like its factor product counterpart, a new factor with all possible assignments born from combining all variables and whose values correspond to the element-wise sum of values. We also look for a way to max marginalize a factor over a variable v, meaning that we obtain the highest probability of the remaining variables once v is set.

The changes to our Factor Operations in vectorized form are trivial.

```python Max Sum Factor Operations
def sum(fA, fB, norma=True):
    '''expanding factors to the whole set of variables, then we can sum element-wise'''
    allVars = sorted(list(set(fA.variables) | set(fB.variables)))
    f = Factor.Factor(allVars)
    FA = expand_rvars(allVars, fA)
    FB = expand_rvars(allVars, fB)
    f.values = FA.values + FB.values
    if norma:
        f.values = normalize(f.values)
    return f

def max_marginalize(fA, v):
    new_vs = [e for e in fA.variables if e != v ]
    if new_vs==[]:
        raise Exception("Error: Resultant factor has empty scope")
    f = Factor.Factor(new_vs)
    pos_m = fA.variables.index(v)
    f.values = np.max(fA.values, axis=pos_m)
    return f
```

Finally, we need to change the clique calibration code to infer a MAP from it. We will assume that the potentials are as is and only at calibration, if we look for the MAP we signal the Tree and for calibration purposes it converts to log space and uses factor sum and max marginalization instead of factor product and standard marginalization.

```python Calibration for MAP
class CliqueTree(UndGraph, object):
    ...
    def mssg(self, from_v, to_w, isMax=False):
        # collect all mssg arriving at v
        mess = []
        neighbors = self.adj[from_v]
        for n in neighbors:
            if n!=to_w:
                pos = self.adj[n].index(from_v)
                msg = self.delta[n][pos]
                mess.append(msg)

        # take the the initial Psi (and log if needed)
        d = copy.copy(self.factors[from_v])
        if isMax==True:
            d.values = np.log(d.values)

        # multiply/sum by incoming messages
        for ms in mess:
            if isMax==True:
                d = FactorOperations.sum(d, ms, False)
            else:
                d = FactorOperations.multiply(d, ms, True)

        # marginalized to setsep vars
        for n in d.variables:
            if n not in (self.box[from_v] & self.box[to_w]):
                if isMax==True:
                    d = FactorOperations.max_marginalize(d, n)
                else:
                    d = FactorOperations.marginalize(d, n)
        return d

    def calibrate(self, isMax=False):
        self.beta = [None]*self.V
        # compute messages
        for e in self.computePath():
            from_v, to_w = e
            pos_to = self.adj[from_v].index(to_w)
            self.delta[from_v][pos_to] = self.mssg(from_v, to_w, isMax)
        
        # compute the beliefs
        for v in range(self.V):
            belief = copy.copy(self.factors[v])
            if isMax==True:
                belief.values = np.log(belief.values)
            for w in self.adj[v]:
                pos = self.adj[w].index(v)
                delta = self.delta[w][pos]
                if isMax==True:
                    belief = FactorOperations.sum(belief, delta, False)
                else:
                    belief = FactorOperations.multiply(belief, delta, False)
            self.beta[v] = belief
```