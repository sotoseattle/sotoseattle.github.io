---
layout: post
title: "Loopy Belief Propagation (I)"
date: 2014-02-6 08:01
comments: true
categories: PGN, theory, inference
---

After a few days sick as a dog, in which I also lost 3 kilograms (great diet), I am back in the saddle, ready to code the 5th assignment of PGM. It will all be about loopy belief propagation as a way to compute approximate marginals and in contrast with the exact inference derived from our clique trees.

To do so we use a Pairwise Markov Grid, with multiple connections between variables that produce clique trees with nodes too big for efficient computation. Here is an example with 3 nodes per side:

{% img center /images/feb14/toy_grid.png 400 Small Pairwise Markov Grid%}

A simple and self-explanatory code to produce the graph would be the following (pay attention to the assignment of weights in and off diagonals):

```python 
class ToyNetwork(UndGraph, object):
    def __init__(self, n=4, weights=[0.5, 0.5]): # n is number of variables per side in grid
        on_diag, off_diag = weights
        c = 2   # fixed cardinality of all vars
        V = n*n
        self.factors, f_pair = [], []
        v = [Rvar.Rvar(i, c) for i in range(V)]
        super(ToyNetwork, self).__init__([[e] for e in v])
        
        for row in range(n):
            for col in range(n):
                pos = row*n + col
                f = Factor.Factor([v[pos]])  # create singleton factor
                singleton_values = [0.4, 0.6] if (pos < V/2) else [0.6, 0.4]
                f.fill_values(singleton_values)
                self.factors.append(f)
                
                links = []
                if row>0:      # add above
                    links.append((row-1)*n + col)
                if col>0:      # add to left
                    links.append(row*n + col - 1)
                for l in links:
                    f = Factor.Factor(sorted([v[l], v[pos]])
                    f.fill_values([on_diag, off_diag, off_diag, on_diag])
                    f_pair.append(f)
        
        self.factors.extend(f_pair)
        for fu in self.factors:
            self.connectAll([self.index_var(v) for v in fu.variables])

t = ToyNetwork(3)
print t.adj
print t.factors[10].values
```

If we build a clique tree from it through variable elimination we end up with the following:

{% img center /images/feb14/ct_toy_grid.png 500 Clique Tree%}

That inner node is way too big for such a small net. As we grow the grid, the inner nodes grow exponentially in complexity, making it computationally intractable. Instead of trying to find an efficient clique tree to compute the exact marginals in just two passes, we could start with a more messy cluster graph, something that is not a tree, and calibrate it until convergence (or wherabouts) to get to good-enough marginals.

The first default in the land of cluster graphs is the Bethe Cluster Graph. Its construction is immediate, get all factors as nodes and connect them to singleton factors made of the encompassed variables. Here is the Bethe derived from the previous Pairwise Markov Grid.

{% img center /images/feb14/bethe_toy_grid.png 500 Bether Cluster Graph%}

```python Bethe Cluster Graph
class BetheNetwork(UndGraph, object):
    
    def __init__(self, singletonFactors, MultivarFactors):
        listOfFactors = singletonFactors
        n_singles = len(listOfFactors)
        
        listOfFactors.extend(MultivarFactors)
        set_vars = [sorted(set(fu.variables)) for fu in listOfFactors]
        super(BetheNetwork, self).__init__(set_vars)
        
        self.factors = listOfFactors
        
        for i in range(n_singles, len(listOfFactors)):
            for v in self.box[i]:
                for j in range(n_singles):
                    if v in self.box[j] and i!=j:
                        self.addEdge(i, j)

n = 3
t1 = ToyNetwork(n)
B = BetheNetwork(t1.factors[:n*n], t1.factors[n*n:])
print B.box
```
