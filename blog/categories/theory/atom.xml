<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: theory, | SotoSeattle]]></title>
  <link href="http://sotoseattle.github.io/blog/categories/theory/atom.xml" rel="self"/>
  <link href="http://sotoseattle.github.io/"/>
  <updated>2017-04-15T12:34:57-07:00</updated>
  <id>http://sotoseattle.github.io/</id>
  <author>
    <name><![CDATA[Javier Soto]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Loopy Belief Propagation (III)]]></title>
    <link href="http://sotoseattle.github.io/blog/2014/02/08/LBP-3/"/>
    <updated>2014-02-08T08:01:00-08:00</updated>
    <id>http://sotoseattle.github.io/blog/2014/02/08/LBP-3</id>
    <content type="html"><![CDATA[<p>These are different approaches to improve convergence and accuracy of the marginals.</p>

<h2 id="smoothing-messages">1. Smoothing Messages</h2>

<p>Very easy to implement. When we compute every new message, instead of updating the delta, we update with smoothing: <code>coef*(new delta) + (1-coef)*(prev stored delta)</code>. This slows convergence in one hand but also avoids big jumps in the beliefs, giving time to achieve convergence at a more controlled pace. Trying for different coeficients I did not improve the marginals.</p>

<h2 id="tree-reparametrization">2. Tree Reparametrization</h2>

<p>Also easy to implement. Instead of using BFS for message scheduling of all nodes, we find a set of trees in the graph so all edges are covered. It is better if we have spanning trees (as long as possible). Then we propagate like with Clique Trees, only twice, forward and backward. The easiest way to get trees from a graph is using Depth First Search (DFS). Still, I don’t know how to get the minimum set of trees that encompass the whole graph, and I had to do it by hand :( Here is an example of 2 trees that span the grid:</p>

<p><img class="center" src="/images/feb14/TRP.png" width="500" title="Trees for LBP" ></p>

<p>```python DFS
class DFS_Paths:
    def <strong>init</strong>(self, G, s):
        self.G = G
        self.source = s
        self.discoveryPath = [] # only the forward path, add backwards
        V = self.G.V
        self.marked = [False]<em>V
        self.edgeTo = [None]</em>V
        self.dfs(self.source) # start only at designated root
        pass</p>

<pre><code>def dfs(self, v):
    self.marked[v] = True
    for w in self.G.adj[v]:
        if self.marked[w]==False:
            self.discoveryPath.append([v,w])
            self.dfs(w)
            self.edgeTo[w] = v
    pass

def pathTo(self, v):
    if self.marked[v]==False:
        return None
    else:
        path = [v]
        x = v
        while x != self.source: 
            x = self.edgeTo[x]
            path.insert(0,x)
        return path ```
</code></pre>

<p>When I run on indiscriminate sets of trees I converge to the bad marginals. But if I use two trees, one long spanning DFS tree plus a manually computed one for the missed edges, I get somewhat better results (sqr error from 0.99 to 0.75):</p>

<table class="widetable">
  <thead>
    <tr>
      <th style="text-align: center">var</th>
      <th style="text-align: right">exact marginal</th>
      <th style="text-align: right">approx. marg (LBP)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: right">0.537310955208</td>
      <td style="text-align: right">0.723905954527</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: right">0.556558936419</td>
      <td style="text-align: right">0.728300716867</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: right">0.552439017812</td>
      <td style="text-align: right">0.592195736634</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: right">0.573509953445</td>
      <td style="text-align: right">0.835859875384</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: right">0.6</td>
      <td style="text-align: right">0.911873353528</td>
    </tr>
    <tr>
      <td style="text-align: center">5</td>
      <td style="text-align: right">0.607090867757</td>
      <td style="text-align: right">0.900624901637</td>
    </tr>
    <tr>
      <td style="text-align: center">6</td>
      <td style="text-align: right">0.611810074317</td>
      <td style="text-align: right">0.8791687735</td>
    </tr>
    <tr>
      <td style="text-align: center">7</td>
      <td style="text-align: right">0.621715017707</td>
      <td style="text-align: right">0.927292899198</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: right">0.626241528067</td>
      <td style="text-align: right">0.905241175589</td>
    </tr>
  </tbody>
</table>
<p><br /></p>

<h2 id="residual-belief-propagation">3. Residual Belief Propagation</h2>

<p>This last effort is based on the fact that not all messgaes have the same importance. Some change the beliefs a great deal, while others are less important. It is easy to look at the way messages achieve convergence, andd see that not all reach equilibrium at the same time. The same happens with the betas.</p>

<p>What I did was implement a priority queue, and as compute each message I store it in the queue with a key that measures how much the message changed. Since all messages are univariate (check cluster graph and realize that there are only pairwise potentials), each message has two values (p, 1-p). The measure I use is the abs of the difference in p. The first pass (BFS) goes through all edges and computes all messages, but starting with the second pass, we compute only the messages that change beyond a tolerance and ordered so the more important run first. </p>

<p>```python Calibrate with RBP
def calibrate(self):
    self.beta = [None]*self.V</p>

<pre><code>path = self.computePath()
q = PriorityQueue()

keep_going = True
cycles, messages = 0, 0
while keep_going:
    cycles +=1
    keep_going = False
    for e in path:
        from_v, to_w = e
        pos_to = self.adj[from_v].index(to_w)
        messages +=1
        prev_res = self.delta[from_v][pos_to].values
        self.delta[from_v][pos_to] = self.mssg(from_v, to_w)
        new_res = self.delta[from_v][pos_to].values
        
        mag = abs(new_res[0] - prev_res[0])/prev_res[0]
        if not np.allclose(new_res, prev_res, 1e-6):
            q.put({abs(mag):[from_v, to_w]})
            keep_going = True
        
    if cycles&gt;1000:
        ...
    
    path = []
    while not q.empty():
        a = q.get()
        path.append(a.values()[0])
    path.reverse() # because it is a minQ
                
print 'Cycles:', cycles, 'Messages passed', messages
# compute the beliefs
... ```
</code></pre>

<p>This way we only need 3 cycles and 104 messages. The first cycle goes through all 48 edges. the second also computes 48 messages but in a different order (prioritized by heuristic importance), and the third only comutes 8 messages. The results are even better:</p>

<table class="widetable">
  <thead>
    <tr>
      <th style="text-align: center">var</th>
      <th style="text-align: right">exact marginal</th>
      <th style="text-align: right">approx. marg (LBP)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: right">0.537310955208</td>
      <td style="text-align: right">0.614445509854</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: right">0.556558936419</td>
      <td style="text-align: right">0.632046274666</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: right">0.552439017812</td>
      <td style="text-align: right">0.592793285825</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: right">0.573509953445</td>
      <td style="text-align: right">0.699814842287</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: right">0.6</td>
      <td style="text-align: right">0.759645004711</td>
    </tr>
    <tr>
      <td style="text-align: center">5</td>
      <td style="text-align: right">0.607090867757</td>
      <td style="text-align: right">0.749109157114</td>
    </tr>
    <tr>
      <td style="text-align: center">6</td>
      <td style="text-align: right">0.611810074317</td>
      <td style="text-align: right">0.739850591712</td>
    </tr>
    <tr>
      <td style="text-align: center">7</td>
      <td style="text-align: right">0.621715017707</td>
      <td style="text-align: right">0.822523867844</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: right">0.626241528067</td>
      <td style="text-align: right">0.848549594174</td>
    </tr>
  </tbody>
</table>
<p><br /></p>

<p>Square distance error is 0.42. If instead of using the BSF as the initial path, we compute all messages and create an initial path based on a priority queue as before, the error can be taken further down to 0.33.</p>

<table class="widetable">
  <thead>
    <tr>
      <th style="text-align: center">var</th>
      <th style="text-align: right">exact marginal</th>
      <th style="text-align: right">approx. marg (LBP)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: right">0.537310955208</td>
      <td style="text-align: right">0.399020732163</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: right">0.556558936419</td>
      <td style="text-align: right">0.378280542986</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: right">0.552439017812</td>
      <td style="text-align: right">0.443100330486</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: right">0.573509953445</td>
      <td style="text-align: right">0.465753424658</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: right">0.6</td>
      <td style="text-align: right">0.641605971227</td>
    </tr>
    <tr>
      <td style="text-align: center">5</td>
      <td style="text-align: right">0.607090867757</td>
      <td style="text-align: right">0.662337662338</td>
    </tr>
    <tr>
      <td style="text-align: center">6</td>
      <td style="text-align: right">0.611810074317</td>
      <td style="text-align: right">0.641605971227</td>
    </tr>
    <tr>
      <td style="text-align: center">7</td>
      <td style="text-align: right">0.621715017707</td>
      <td style="text-align: right">0.770344431088</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: right">0.626241528067</td>
      <td style="text-align: right">0.719502074689</td>
    </tr>
  </tbody>
</table>
<p><br /></p>

<p>And finally, if instead of prioritizing the queue based on the importance of the messages we do it based on how each new message changes the marginalized belief of the receiving node we lower the error further to 0.24, although we need to cycle 13 times and pass 296 messages.</p>

<table class="widetable">
  <thead>
    <tr>
      <th style="text-align: center">var</th>
      <th style="text-align: right">exact marginal</th>
      <th style="text-align: right">approx. marg (LBP)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"> </td>
      <td style="text-align: right"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: right">0.537310955208</td>
      <td style="text-align: right">0.444436529385</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: right">0.556558936419</td>
      <td style="text-align: right">0.605683356431</td>
    </tr>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: right">0.552439017812</td>
      <td style="text-align: right">0.494869086601</td>
    </tr>
    <tr>
      <td style="text-align: center">3</td>
      <td style="text-align: right">0.573509953445</td>
      <td style="text-align: right">0.562421013105</td>
    </tr>
    <tr>
      <td style="text-align: center">4</td>
      <td style="text-align: right">0.6</td>
      <td style="text-align: right">0.692305538097</td>
    </tr>
    <tr>
      <td style="text-align: center">5</td>
      <td style="text-align: right">0.607090867757</td>
      <td style="text-align: right">0.64302214095</td>
    </tr>
    <tr>
      <td style="text-align: center">6</td>
      <td style="text-align: right">0.611810074317</td>
      <td style="text-align: right">0.682604471501</td>
    </tr>
    <tr>
      <td style="text-align: center">7</td>
      <td style="text-align: right">0.621715017707</td>
      <td style="text-align: right">0.745950622502</td>
    </tr>
    <tr>
      <td style="text-align: center">8</td>
      <td style="text-align: right">0.626241528067</td>
      <td style="text-align: right">0.748513253977</td>
    </tr>
  </tbody>
</table>
<p><br /></p>

<p>```python Code to compute the magnitude based on belief change
def magnitude(self, from_v, to_w):
    beta = copy.copy(self.factors[to_w])
    past_beta = copy.copy(beta)</p>

<pre><code>affected_var = [e for e in beta.variables if e not in self.box[from_v]]
for x in self.adj[to_w]:
    posX = self.adj[x].index(to_w)
    delta = self.delta[x][posX]
    beta = FactorOperations.multiply(beta, delta, True) #### NORMALIZING
    
if affected_var!=[]:
    past_beta = FactorOperations.marginalize(past_beta, affected_var[0])
    beta = FactorOperations.marginalize(beta, affected_var[0])            
mag = abs(beta.values[0]-past_beta.values[0])/past_beta.values[0]
return mag ```
</code></pre>

<p>Nevertheless, although it gives good results for a 9 node Ising grid, the more the nodes the worse it works. The RBP is the best approach found and I am sure that with a better designed key for the queue (to show which messages should be prioritized) bigger grids can also be optimized.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Loopy Belief Propagation (I)]]></title>
    <link href="http://sotoseattle.github.io/blog/2014/02/06/LBP-I/"/>
    <updated>2014-02-06T08:01:00-08:00</updated>
    <id>http://sotoseattle.github.io/blog/2014/02/06/LBP-I</id>
    <content type="html"><![CDATA[<p>After a few days sick as a dog, in which I also lost 3 kilograms (great diet), I am back in the saddle, ready to code the 5th assignment of PGM. It will all be about loopy belief propagation as a way to compute approximate marginals and in contrast with the exact inference derived from our clique trees.</p>

<p>To do so we use a Pairwise Markov Grid, with multiple connections between variables that produce clique trees with nodes too big for efficient computation. Here is an example with 3 nodes per side:</p>

<p><img class="center" src="/images/feb14/toy_grid.png" width="400" title="Small Pairwise Markov Grid" ></p>

<p>A simple and self-explanatory code to produce the graph would be the following (pay attention to the assignment of weights in and off diagonals):</p>

<p>```python 
class ToyNetwork(UndGraph, object):
    def <strong>init</strong>(self, n=4, weights=[0.5, 0.5]): # n is number of variables per side in grid
        on_diag, off_diag = weights
        c = 2   # fixed cardinality of all vars
        V = n*n
        self.factors, f_pair = [], []
        v = [Rvar.Rvar(i, c) for i in range(V)]
        super(ToyNetwork, self).<strong>init</strong>([[e] for e in v])</p>

<pre><code>    for row in range(n):
        for col in range(n):
            pos = row*n + col
            f = Factor.Factor([v[pos]])  # create singleton factor
            singleton_values = [0.4, 0.6] if (pos &lt; V/2) else [0.6, 0.4]
            f.fill_values(singleton_values)
            self.factors.append(f)
            
            links = []
            if row&gt;0:      # add above
                links.append((row-1)*n + col)
            if col&gt;0:      # add to left
                links.append(row*n + col - 1)
            for l in links:
                f = Factor.Factor(sorted([v[l], v[pos]])
                f.fill_values([on_diag, off_diag, off_diag, on_diag])
                f_pair.append(f)
    
    self.factors.extend(f_pair)
    for fu in self.factors:
        self.connectAll([self.index_var(v) for v in fu.variables])
</code></pre>

<p>t = ToyNetwork(3)
print t.adj
print t.factors[10].values
```</p>

<p>If we build a clique tree from it through variable elimination we end up with the following:</p>

<p><img class="center" src="/images/feb14/ct_toy_grid.png" width="500" title="Clique Tree" ></p>

<p>That inner node is way too big for such a small net. As we grow the grid, the inner nodes grow exponentially in complexity, making it computationally intractable. Instead of trying to find an efficient clique tree to compute the exact marginals in just two passes, we could start with a more messy cluster graph, something that is not a tree, and calibrate it until convergence (or wherabouts) to get to good-enough marginals.</p>

<p>The first default in the land of cluster graphs is the Bethe Cluster Graph. Its construction is immediate, get all factors as nodes and connect them to singleton factors made of the encompassed variables. Here is the Bethe derived from the previous Pairwise Markov Grid.</p>

<p><img class="center" src="/images/feb14/bethe_toy_grid.png" width="500" title="Bether Cluster Graph" ></p>

<p>```python Bethe Cluster Graph
class BetheNetwork(UndGraph, object):</p>

<pre><code>def __init__(self, singletonFactors, MultivarFactors):
    listOfFactors = singletonFactors
    n_singles = len(listOfFactors)
    
    listOfFactors.extend(MultivarFactors)
    set_vars = [sorted(set(fu.variables)) for fu in listOfFactors]
    super(BetheNetwork, self).__init__(set_vars)
    
    self.factors = listOfFactors
    
    for i in range(n_singles, len(listOfFactors)):
        for v in self.box[i]:
            for j in range(n_singles):
                if v in self.box[j] and i!=j:
                    self.addEdge(i, j)
</code></pre>

<p>n = 3
t1 = ToyNetwork(n)
B = BetheNetwork(t1.factors[:n<em>n], t1.factors[n</em>n:])
print B.box
```</p>
]]></content>
  </entry>
  
</feed>
