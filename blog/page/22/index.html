
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>SotoSeattle</title>
  <meta name="author" content="Javier Soto">

  
  <meta name="description" content="My first ML program is going to be the Kaggle OCR digit competition. The original data comes in two files: train.csv and a test.csv. Each file &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://sotoseattle.github.io/blog/page/22">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="" rel="alternate" title="SotoSeattle" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/lib/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>
<link href='http://fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>
<!-- MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["$$","$$"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  

</head>

<body   class="collapse-sidebar sidebar-footer" >
  <header role="banner">
	<div class="header-title"><a href="/">SotoSeattle</a></div>


	<br><div class="header-subtitle">Curious Coder & Investor</div>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
<!--   <li><a href="" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li> -->
  
  <li class='icon'>
    <a href="https://github.com/sotoseattle/">
      <img src="/images/logos/github_icon.png" width="36" height="27">
      </img>
    </a>
  </li>
  <li class='icon'>
    <a href="https://www.linkedin.com/in/sotoseattle/">
      <img src="/images/logos/linkedin-256.png"  width="27" height="27">
      </img>
    </a>
  </li>
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:sotoseattle.github.io" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
<!--   <li><a href="projects/">Projects</a></li> -->
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <!-- <li><a href="/images/Javier_Soto_resume.pdf">Resume</a></li> -->
  <li><a href="/about">About</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2013/10/05/Kaggle-Digit-OCR/">Kaggle Digit OCR: The Data</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2013-10-05T09:02:00-07:00" pubdate data-updated="true">Oct 5<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>My first ML program is going to be the <a href="http://www.kaggle.com/c/digit-recognizer">Kaggle OCR digit competition</a>. </p>

<p>The original data comes in two files: train.csv and a test.csv. Each file contain gray-scale images of hand-drawn digits, from zero through nine.</p>

<p>Each image is 28 pixels in height and 28 pixels in width, for a total of 784 pixels in total. Each pixel has a single pixel-value associated with it, indicating the lightness or darkness of that pixel, with higher numbers meaning darker. This pixel-value is an integer between 0 and 255, inclusive.</p>

<p>The training data set, (train.csv), has 785 columns and 42.0001 rows. The first column, called “label”, is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image. The first row is a header and each subsequent row holds an image in vectorized form for a total of 42.000 images</p>

<p>The test file is similar but without a label column, which is the goal of the competition.</p>

<p>We can visualize each handwritten digit with the following code:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>visualize handwritten digit</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="n">x</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>	<span class="c"># all the training images</span>
</span><span class="line"><span class="n">y</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>	<span class="c"># all the training labels</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">visualize</span><span class="p">(</span><span class="n">example_number</span><span class="p">):</span>
</span><span class="line">	<span class="k">print</span> <span class="s">&#39;should be a&#39;</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">example_number</span><span class="p">]</span>
</span><span class="line">	<span class="n">matplotlib</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">gray</span><span class="p">()</span>
</span><span class="line">	<span class="n">matplotlib</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">example_number</span><span class="p">,:]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">))</span>
</span><span class="line">	<span class="n">matplotlib</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>For example, from train.csv, the 6<sup>th</sup> row is: [7, 0, 0, …, 82, 152, 71, 51, 51, …, 0, 0, 0, 0, 0.]</p>

<p>Where the first digit tells us that the “real” number is a “7” and the following 784 numbers can be reshaped into a grid to show the following image:</p>

<p><img class="center" src="/images/kaggle_ocr/mnist_good_7.png" width="400" height="400" title="Seven" /></p>

<p>Not everything is so clear cut. Two additional examples from the training set: a One and a Seven, which could be misclassified even by hand.</p>

<div style="text-align:center">
<img src="/images/kaggle_ocr/mnist_1.png" width="400" height="400" title="One" />
<img src="/images/kaggle_ocr/mnist_7.png" width="400" height="400" title="Seven" />
</div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2013/10/04/Softmax-IV/">Softmax Theory: $θ$</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2013-10-04T09:02:00-07:00" pubdate data-updated="true">Oct 4<span>th</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>To train the model and find the parameters we need some sort of gradient descent algorithm. In python <a href="http://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">fmin_bfgs</a> takes way too long and hogs memory, while it’s sister <a href="http://en.wikipedia.org/wiki/Limited-memory_BFGS">fmin_l_bfgs_b</a> is much faster and lighter.</p>

<p>To call it we need to consider the following issues:</p>

<ul>
  <li>we need to pass the cost and gradient function separately (unlike in Octave).</li>
  <li>the first argument of the function and of its derivation has to be the parameter to be optimized.</li>
  <li>tinit is an initial set of parameters from which to start the search, a good compromise is <code>0.005 * np.random.rand(labels, n)</code>.</li>
  <li>for the l_bfgs to work the gradient format must be rolled out (not in matrix form).</li>
  <li>the optimizing algorithm provides additional useful information [f, d] about the search performed.</li>
  <li>other options, like the maximum number of iterations to perform or the convergence tolerance can be researched online.</li>
</ul>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>optimizing thetas</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class="line"><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">fmin_l_bfgs_b</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">optimizeThetas</span><span class="p">(</span><span class="n">tinit</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">GT</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">,</span> <span class="n">l</span><span class="p">):</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
</span><span class="line">        <span class="k">return</span> <span class="n">j</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">GT</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
</span><span class="line">    <span class="k">def</span> <span class="nf">fprime</span><span class="p">(</span><span class="n">w</span><span class="p">):</span>
</span><span class="line">        <span class="k">return</span> <span class="n">v</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">GT</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">    <span class="p">[</span><span class="n">thetas</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">d</span><span class="p">]</span> <span class="o">=</span> <span class="n">fmin_l_bfgs_b</span><span class="p">(</span><span class="n">func</span><span class="o">=</span><span class="n">f</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">tinit</span><span class="p">,</span> <span class="n">fprime</span><span class="o">=</span><span class="n">fprime</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">400</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">thetas</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
  
    
      <h1 class="entry-title"><a href="/blog/2013/10/03/Softmax-III/">Softmax Theory: $∇(θ)$</a></h1>
      
      
    
      <p class="meta">
        








  


<time datetime="2013-10-03T09:02:00-07:00" pubdate data-updated="true">Oct 3<span>rd</span>, 2013</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There is no known closed-form way to solve for the minimum of $J(θ)$, and thus as usual we’ll resort to an iterative optimization algorithm such as gradient descent or L-BFGS. Taking derivatives, one can show that the gradient is:</p>

<script type="math/tex; mode=display">
\begin{align}
\nabla_{\theta_j} J(\theta) = - \frac{1}{m} \sum_{i=1}^{m}{ \left[ x^{(i)} ( 1\{ y^{(i)} = j\}  - p(y^{(i)} = j | x^{(i)}; \theta) ) \right]  } + \lambda \theta_j
\end{align}
</script>

<p>By minimizing $J(θ)$ with respect to $θ$, we will have a working implementation of softmax regression. Note that the gradient output is flatten from a matrix form to a vector form. This is needed format for the gradient descent algorithm to work.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>gradient function</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">v</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">groundTruth</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">,</span> <span class="n">regul_lambda</span><span class="p">):</span>
</span><span class="line">    <span class="n">thetas</span> <span class="o">=</span> <span class="n">thetas</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">numLabels</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span class="line">    <span class="n">hx</span> <span class="o">=</span> <span class="n">h</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</span><span class="line">    <span class="n">m</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span class="line">    <span class="n">grad</span> <span class="o">=</span> <span class="p">((</span><span class="n">groundTruth</span><span class="o">-</span><span class="n">hx</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">/</span><span class="p">(</span><span class="o">-</span><span class="n">m</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">regul_lambda</span><span class="o">*</span><span class="n">thetas</span><span class="p">)</span>
</span><span class="line">    <span class="n">grad</span> <span class="o">=</span> <span class="n">grad</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">grad</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="checking-the-gradient-computation">checking the gradient computation</h2>

<p>It is very a healthy habit to check gradients numerically before proceeding to train the model. The norm of the difference between the numerical gradient and your analytical gradient should be small, on the order of 10 − 9. The following code uses some random data to compare the above gradient against a numerical approximation based on the formula</p>

<p>The key to compute the gradient by hand is to keep all $θ$ fixed while we change a single one by a small amount (epsilon) $\theta_j := \theta_j - \alpha \nabla_{\theta_j} J(\theta) (for each j=1,\ldots,k)$.</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span>checking gradient with numerical approximation</span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</span><span class="line">
</span><span class="line"><span class="k">def</span> <span class="nf">grad_by_hand</span><span class="p">(</span><span class="n">thetas</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">groundTruth</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">,</span> <span class="n">regul_lambda</span><span class="p">):</span>
</span><span class="line">    <span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-4</span>
</span><span class="line">    <span class="n">t</span> <span class="o">=</span> <span class="n">thetas</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span class="line">    <span class="n">n</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">size</span>
</span><span class="line">    <span class="n">grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">n</span><span class="p">,))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">&#39;float64&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
</span><span class="line">        <span class="n">t1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</span><span class="line">        <span class="n">t2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
</span><span class="line">        <span class="n">t1</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">epsilon</span>
</span><span class="line">        <span class="n">t2</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-=</span> <span class="n">epsilon</span>
</span><span class="line">        <span class="n">a</span> <span class="o">=</span> <span class="n">j</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">groundTruth</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">,</span> <span class="n">regul_lambda</span><span class="p">)</span>
</span><span class="line">        <span class="n">b</span> <span class="o">=</span> <span class="n">j</span><span class="p">(</span><span class="n">t2</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">groundTruth</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">,</span> <span class="n">regul_lambda</span><span class="p">)</span>
</span><span class="line">        <span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span><span class="o">-</span><span class="n">b</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">epsilon</span><span class="p">)</span>
</span><span class="line">    <span class="k">return</span> <span class="n">grad</span>
</span><span class="line">
</span><span class="line"><span class="n">x_check</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
</span><span class="line"><span class="n">y_check</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
</span><span class="line"><span class="n">g_check</span> <span class="o">=</span> <span class="n">soft</span><span class="o">.</span><span class="n">groundTruth</span><span class="p">(</span><span class="n">y_check</span><span class="p">,</span> <span class="n">numLabels</span><span class="p">)</span>
</span><span class="line"><span class="n">t_check</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">&#39;float64&#39;</span><span class="p">)</span>
</span><span class="line"><span class="n">g_theo</span> <span class="o">=</span> <span class="n">v</span><span class="p">(</span><span class="n">t_check</span><span class="p">,</span> <span class="n">x_check</span><span class="p">,</span> <span class="n">g_check</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
</span><span class="line"><span class="n">g_hand</span> <span class="o">=</span> <span class="n">grad_by_hand</span><span class="p">(</span><span class="n">t_check</span><span class="p">,</span> <span class="n">x_check</span><span class="p">,</span> <span class="n">g_check</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
</span><span class="line"><span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g_hand</span> <span class="o">-</span> <span class="n">g_theo</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">g_hand</span> <span class="o">+</span> <span class="n">g_theo</span><span class="p">)</span>
</span><span class="line"><span class="k">assert</span> <span class="n">diff</span> <span class="o">&lt;=</span> <span class="mf">1e-9</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/23/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/blog/page/21/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/11/18/Unicorns/">Gazelles and Unicorns</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/06/18/Founders/">Psyc Founders Out</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/12/05/ruby-continuations/">Ruby Continuations</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/04/Seattlerb-GoL/">Seattle Ruby Game Of Life</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/03/01/CodeFellows/">Article Published</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 -  Javier Soto <br/>
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a> + <a href="https://github.com/ioveracker/mnml">mnml</a>.
	  
  </span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'sotoseattle';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
